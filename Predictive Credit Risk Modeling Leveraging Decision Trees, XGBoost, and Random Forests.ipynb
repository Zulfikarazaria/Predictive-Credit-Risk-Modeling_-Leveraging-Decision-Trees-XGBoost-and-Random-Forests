{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Credit Risk Modeling: Leveraging Decision Trees, XGBoost, and Random Forests\n",
    "## Zulfikar Azaria Rahman\tID/X Partners (Rakamin Academy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    auc,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Suppress warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('loan_data_2007_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Preliminary Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are features that are not useful, hence the need to remove features. Examples include features that are unique id, free text, empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = [\n",
    "    'Unnamed: 0' \n",
    "    ,'id'\n",
    "    , 'member_id'\n",
    "    , 'url'\n",
    "    , 'desc'\n",
    "    , 'zip_code' \n",
    "    , 'annual_inc_joint'\n",
    "    , 'dti_joint'\n",
    "    , 'verification_status_joint'\n",
    "    , 'open_acc_6m'\n",
    "    , 'open_il_6m'\n",
    "    , 'open_il_12m'\n",
    "    , 'open_il_24m'\n",
    "    , 'mths_since_rcnt_il'\n",
    "    , 'total_bal_il'\n",
    "    , 'il_util'\n",
    "    , 'open_rv_12m'\n",
    "    , 'open_rv_24m'\n",
    "    , 'max_bal_bc'\n",
    "    , 'all_util'\n",
    "    , 'inq_fi'\n",
    "    , 'total_cu_tl'\n",
    "    , 'inq_last_12m'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Target Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In project credit risk modelling, the main objective is to predict an individual's ability to repay the loan. Therefore, the target variable used should reflect the individual's ability in this regard. In this data set, the variable `loan_status` is a variable that can be used as a target variable because it reflects the performance of each individual in making payments on loans so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loan_status.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_debt = [\n",
    "    'Charged Off' \n",
    "    , 'Default' \n",
    "    , 'Does not meet the credit policy. Status:Charged Off'\n",
    "    , 'Late (31-120 days)'\n",
    "]\n",
    "\n",
    "data['credit_status'] = np.where(data['loan_status'].isin(bad_debt), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['credit_status'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('loan_status', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`term`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['term'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['term'] = data['term'].str.replace(' months', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['term'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`emp_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emp_length'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emp_length'] = data['emp_length'].str.replace('+ years', '')\n",
    "data['emp_length'] = data['emp_length'].str.replace('< 1 year', str(0))\n",
    "data['emp_length'] = data['emp_length'].str.replace(' years', '')\n",
    "data['emp_length'] = data['emp_length'].str.replace(' year', '')\n",
    "data['emp_length'] = data['emp_length'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`earliest_cr_line`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifies `earliest_cr_line` from month-year format to a calculation of how much time has passed since that time. To do this I use 2016-12-01 as reference date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_date = '2016-12-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['earliest_cr_line_date'] = pd.to_datetime(data['earliest_cr_line'], format='%b-%y')\n",
    "data['earliest_cr_line_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mths_since_earliest_cr_line'] = round(pd.to_numeric((pd.to_datetime(reference_date) - data['earliest_cr_line_date']) / np.timedelta64(1, 'm')))\n",
    "data['mths_since_earliest_cr_line'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mths_since_earliest_cr_line.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a strange value, which is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['mths_since_earliest_cr_line']<0][['earliest_cr_line', 'earliest_cr_line_date', 'mths_since_earliest_cr_line']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the negative value is because the Python function misinterpreted the year 62 to be 2062, when it should have been 1962.\n",
    "To solve this I simply changed the negative value to the maximum value of the feature (`mths_since_earliest_cr_line`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['mths_since_earliest_cr_line']<0, 'mths_since_earliest_cr_line'] = data['mths_since_earliest_cr_line'].max()\n",
    "data.drop(['earliest_cr_line', 'earliest_cr_line_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `issue_d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['issue_d_date'] = pd.to_datetime(data['issue_d'], format='%b-%y')\n",
    "data['mths_since_issue_d'] = round(pd.to_numeric((pd.to_datetime(reference_date) - data['issue_d_date']) / np.timedelta64(1, 'm')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mths_since_issue_d'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['issue_d', 'issue_d_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`last_pymnt_d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['last_pymnt_d_date'] = pd.to_datetime(data['last_pymnt_d'], format='%b-%y')\n",
    "data['mths_since_last_pymnt_d'] = round(pd.to_numeric((pd.to_datetime(reference_date) - data['last_pymnt_d_date']) / np.timedelta64(1, 'm')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mths_since_last_pymnt_d'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['last_pymnt_d', 'last_pymnt_d_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`next_pymnt_d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['next_pymnt_d_date'] = pd.to_datetime(data['next_pymnt_d'], format='%b-%y')\n",
    "data['mths_since_next_pymnt_d'] = round(pd.to_numeric((pd.to_datetime(reference_date) - data['next_pymnt_d_date']) / np.timedelta64(1, 'm')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['next_pymnt_d', 'next_pymnt_d_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`last_credit_pull_d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['last_credit_pull_d_date'] = pd.to_datetime(data['last_credit_pull_d'], format='%b-%y')\n",
    "data['mths_since_last_credit_pull_d'] = round(pd.to_numeric((pd.to_datetime(reference_date) - data['last_credit_pull_d_date']) / np.timedelta64(1, 'm')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mths_since_last_credit_pull_d'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['last_credit_pull_d', 'last_credit_pull_d_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating numerical and categorical features\n",
    "nums = []\n",
    "cats = []\n",
    "for i in data.columns:\n",
    "  if data[i].dtype == 'object':\n",
    "    cats.append(i)\n",
    "  else:\n",
    "    nums.append(i)\n",
    "print('jumlah = ',len(nums))\n",
    "print('nums = ',nums)\n",
    "print('jumlah = ',len(cats))\n",
    "print('cats = ',cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary For Numericals Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical statistical sumary\n",
    "data[nums].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary For Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical statistical sumary\n",
    "data[cats].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating numerical and categorical features\n",
    "nums = []\n",
    "cats = []\n",
    "for i in data.columns:\n",
    "  if data[i].dtype == 'object':\n",
    "    cats.append(i)\n",
    "  else:\n",
    "    nums.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data[cats]:\n",
    "  print(f\"Value counts of {col} column\")\n",
    "  print(data[col].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. Drop `application_type`, `policy_code` because it only has 1 unique value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['application_type', 'policy_code', 'sub_grade'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing value\n",
    "Missing = data.isnull().sum() * 100 / len(data)\n",
    "dtypes=[data[col].dtype for col in data.columns]\n",
    "Missing_Value = pd.DataFrame({'data_type':dtypes,\n",
    "                                 'Missing': Missing})\n",
    "Missing_Value.sort_values('Missing', ascending=False, inplace=True)\n",
    "Missing_Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the missing value of `mths_since_last_record` is more than 60%, so I drop the `mths_since_last_record` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['mths_since_last_record', 'mths_since_last_major_derog', 'mths_since_last_delinq'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "\n",
    "corr = numeric_data.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "heatmap = sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.1, annot_kws={\"size\": 8})\n",
    "\n",
    "# Reduce the font size of x and y axis labels\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=10)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=10)\n",
    "\n",
    "plt.title('Correlation Heatmap', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix and take its absolute value\n",
    "corr_matrix = numeric_data.corr().abs()\n",
    "\n",
    "# Taking the top of the correlation matrix (above the diagonal)\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find columns with high correlation (>0.7)\n",
    "drop_hicorr = [column for column in upper.columns if any(upper[column] > 0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['funded_amnt',\n",
    " 'funded_amnt_inv',\n",
    " 'installment',\n",
    " 'out_prncp_inv',\n",
    " 'total_pymnt',\n",
    " 'total_pymnt_inv',\n",
    " 'mths_since_last_pymnt_d',\n",
    " 'mths_since_next_pymnt_d',\n",
    " 'mths_since_last_credit_pull_d'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing value\n",
    "Missing = data.isnull().sum() * 100 / len(data)\n",
    "dtypes=[data[col].dtype for col in data.columns]\n",
    "Missing_Value = pd.DataFrame({'data_type':dtypes,\n",
    "                                 'Missing': Missing})\n",
    "Missing_Value.sort_values('Missing', ascending=False, inplace=True)\n",
    "Missing_Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tot_cur_bal'].fillna(0, inplace=True)\n",
    "data['tot_coll_amt'].fillna(0, inplace=True)\n",
    "data['emp_length'].fillna(0, inplace=True)\n",
    "data['revol_util'].fillna(0, inplace=True)\n",
    "data['collections_12_mths_ex_med'].fillna(0, inplace=True)\n",
    "data['open_acc'].fillna(0, inplace=True)\n",
    "data['delinq_2yrs'].fillna(0, inplace=True)\n",
    "data['pub_rec'].fillna(0, inplace=True)\n",
    "data['inq_last_6mths'].fillna(0, inplace=True)\n",
    "data['total_acc'].fillna(0, inplace=True)\n",
    "data['acc_now_delinq'].fillna(0, inplace=True)\n",
    "data['mths_since_earliest_cr_line'].fillna(0, inplace=True)\n",
    "data['annual_inc'].fillna(data['annual_inc'].mean(), inplace=True)\n",
    "data['total_rev_hi_lim'].fillna(data['total_rev_hi_lim'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows that has missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checking for missing value\n",
    "Missing = data.isnull().sum() * 100 / len(data)\n",
    "dtypes=[data[col].dtype for col in data.columns]\n",
    "Missing_Value = pd.DataFrame({'data_type':dtypes,\n",
    "                                 'Missing': Missing})\n",
    "Missing_Value.sort_values('Missing', ascending=False, inplace=True)\n",
    "Missing_Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicated data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of duplicated data\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is clean now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation & Standardrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_LE = [col for col in data.select_dtypes(include='object').columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for i in cat_LE:\n",
    "   data[i] = le.fit_transform(data[i])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "\n",
    "corr = numeric_data.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "heatmap = sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.1, annot_kws={\"size\": 8})\n",
    "\n",
    "# Reduce the font size of x and y axis labels\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=10)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=10)\n",
    "\n",
    "plt.title('Correlation Heatmap', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Spling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = data.drop('credit_status', axis=1)\n",
    "target = data['credit_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First splitting: pretrain and test\n",
    "feature_pretrain, feature_test, target_pretrain, target_test = train_test_split(feature, target, test_size=0.20, random_state=42)\n",
    "\n",
    "# Second splitting: train and validation\n",
    "feature_train, feature_validation, target_train, target_validation = train_test_split(feature_pretrain, target_pretrain, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "feature_train_scaled = scaler.fit_transform(feature_train)\n",
    "\n",
    "# Transform the validation and test data\n",
    "feature_validation_scaled = scaler.transform(feature_validation)\n",
    "feature_test_scaled = scaler.transform(feature_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform oversampling with SMOTE on the scaled training data\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(feature_train_scaled, target_train)\n",
    "\n",
    "# Check the number of samples before and after oversampling\n",
    "print(\"Jumlah sampel sebelum oversampling:\", len(feature_train))\n",
    "print(\"Jumlah sampel setelah oversampling:\", len(X_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = [\n",
    " ('XGBoost', XGBClassifier()),\n",
    " ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
    " ('Random Forest', RandomForestClassifier(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = []\n",
    "\n",
    "for name, model in Model:\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Prediction and evaluation on validation data\n",
    "    y_pred_train_model = model.predict(feature_validation_scaled)\n",
    "    accuracy_train = accuracy_score(target_validation, y_pred_train_model)\n",
    "    precision_train = precision_score(target_validation, y_pred_train_model)\n",
    "    recall_train = recall_score(target_validation, y_pred_train_model)\n",
    "    f1_train = f1_score(target_validation, y_pred_train_model)\n",
    "    \n",
    "    # Prediction and evaluation on test data\n",
    "    y_pred_test_model = model.predict(feature_test_scaled)\n",
    "    accuracy_test = accuracy_score(target_test, y_pred_test_model)\n",
    "    precision_test = precision_score(target_test, y_pred_test_model)\n",
    "    recall_test = recall_score(target_test, y_pred_test_model)\n",
    "    f1_test = f1_score(target_test, y_pred_test_model)\n",
    "    \n",
    "    results_train.append((name, accuracy_train, precision_train, recall_train, f1_train, accuracy_test, precision_test, recall_test, f1_test))\n",
    "\n",
    "# Create a DataFrame from the result\n",
    "comparison_df_train = pd.DataFrame(results_train, columns=['Model', 'Train Accuracy', 'Train Precision', 'Train Recall', 'Train F1 Score', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1 Score'])\n",
    "\n",
    "print(\"Results:\")\n",
    "print(comparison_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model_name, model_instance, feature_data, target_data, pastel_color):\n",
    "    # Predicted probability on data\n",
    "    y_pred_prob = model_instance.predict_proba(feature_data)[:, 1]\n",
    "\n",
    "    # Calculating the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(target_data, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Display the ROC curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, color=pastel_color, lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve - {model_name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    auc_score = roc_auc_score(target_data, y_pred_prob)\n",
    "    print(f'AUC Score for {model_name}: {auc_score}')\n",
    "\n",
    "pastel = sns.color_palette(\"pastel\", len(Model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (model_name, model_instance) in enumerate(Model):\n",
    "    plot_roc_curve(model_name, model_instance, feature_validation_scaled, target_validation, pastel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (model_name, model_instance) in enumerate(Model):\n",
    "    plot_roc_curve(model_name, model_instance, feature_test_scaled, target_test, pastel[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Summary\n",
    "\n",
    "## Best Performing Model\n",
    "XGBoost is the best-performing model based on all metrics (accuracy, precision, recall, F1 score, and AUC) for both the training and test sets.\n",
    "\n",
    "## Overfitting/Underfitting Analysis\n",
    "- **XGBoost**: The metrics for both training and test sets are very close, indicating no significant overfitting or underfitting. The model generalizes well to unseen data.\n",
    "- **Decision Tree**: The metrics for training and test sets are also quite close, suggesting no significant overfitting or underfitting. However, its overall performance is lower compared to XGBoost and Random Forest, indicating it might be underperforming.\n",
    "- **Random Forest**: The metrics for training and test sets are close, indicating good generalization. However, the recall is slightly lower compared to XGBoost, which might suggest a slight room for improvement.\n",
    "\n",
    "## Hyperparameter Tuning Recommendation\n",
    "- **XGBoost**: Since it is already the best-performing model, hyperparameter tuning could help to further optimize and enhance its performance.\n",
    "- **Decision Tree**: Hyperparameter tuning is recommended to improve its performance and potentially bring it closer to that of XGBoost or Random Forest.\n",
    "- **Random Forest**: Although it performs well, hyperparameter tuning might help improve recall and overall performance.\n",
    "\n",
    "## Conclusion\n",
    "XGBoost is currently the best model. Hyperparameter tuning is advisable for XGBoost and Random Forest to further enhance performance, while Decision Tree requires tuning to potentially achieve significant performance improvements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Recommendations\n",
    "\n",
    "## 1. Credit Approval Process Optimization\n",
    "- **Model Integration:** Use the XGBoost model to speed up credit approval and improve accuracy in assessing creditworthiness.\n",
    "- **Risk Reduction:** Decline high-risk applications and impose stricter terms on medium-risk applicants to reduce non-performing loans (NPLs).\n",
    "\n",
    "## 2. Personalized Product Offers\n",
    "- **Customer Segmentation:** Segment customers by risk profile. Offer aggressive credit products to low-risk customers and stricter terms or safer products to high-risk customers.\n",
    "- **Interest Rate Adjustment:** Provide competitive interest rates for low-risk customers and higher rates for high-risk customers to better price the risk.\n",
    "\n",
    "## 3. Credit Portfolio Management\n",
    "- **Regular Monitoring:** Use the model to regularly assess the risk of the existing credit portfolio and take early action on changing risk profiles.\n",
    "- **Proactive Policies:** Develop proactive policies to manage customers with increasing risk, such as offering loan restructuring programs.\n",
    "\n",
    "## 4. New Product Development\n",
    "- **Innovative Credit Products:** Develop new credit products tailored to different risk segments, like microloans for low-risk customers.\n",
    "- **Credit Insurance:** Offer credit insurance to high-risk customers to mitigate the bank's risk.\n",
    "\n",
    "## 5. Customer Relationship Management (CRM)\n",
    "- **Retention Strategies:** Identify low-risk customers at risk of leaving and offer incentives like increased credit limits or loyalty programs to retain them.\n",
    "- **Proactive Handling:** Proactively manage customers showing signs of financial distress before they default, such as offering loan restructuring or financial counseling.\n",
    "\n",
    "## Summary\n",
    "The XGBoost model has proven to be effective in predicting credit risk. By integrating this model into various business processes, the bank can improve risk management, optimize the credit portfolio, enhance customer service. These recommendations not only help in reducing potential losses but also in boosting profitability and business sustainability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
